


          
# Elasticsearch Full Replicator

Инструмент для полной репликации данных между кластерами Elasticsearch

## Описание
Elasticsearch Full Replicator - это Python-скрипт для надежной репликации данных между кластерами Elasticsearch. Инструмент предоставляет функциональность, аналогичную Cross Cluster Replication (CCR), но с дополнительными возможностями и гибкостью настройки.

## Основные возможности

### Репликация данных
- Полная репликация индексов между кластерами
- Инкрементальная синхронизация с использованием временных меток
- Выборочная репликация отсутствующих индексов
- Сохранение настроек и маппингов исходных индексов
- Поддержка фильтрации индексов по шаблонам

### Проверка целостности
- Генерация и проверка контрольных сумм документов
- Верификация успешности репликации
- Подробное логирование процесса и ошибок
- Статистика по обработанным документам

### Производительность
- Параллельная обработка с настраиваемым количеством потоков
- Параллельная репликация нескольких индексов (до 5 одновременно)
- Оптимизированная пакетная обработка документов (до 100 параллельных потоков на индекс)
- Настраиваемые таймауты и повторные попытки
- Поддержка HTTP-сжатия
- Автоматическое отключение refresh_interval во время репликации
- Асинхронная обработка bulk-операций

### Конфигурация производительности
```yaml
replication:
  # Количество параллельных потоков для обработки документов в рамках одного индекса
  max_workers: 100
  
  # Количество индексов, реплицируемых одновременно
  max_index_workers: 5
  
  # Размер пакета документов для bulk-операций
  batch_size: 10000
  
  # Время удержания scroll-контекста
  scroll_time: "60m"
  
  # Таймаут запросов
  request_timeout: 300
  
  # Количество повторных попыток при ошибках
  max_retries: 5
  continuous: false
  interval: 3600
  timestamp_field: "@timestamp"
  checksum_field: "_doc_checksum"
  exclude_patterns:
    - "^\\..*"
    - ".*_backup$"
```

## Использование

### Базовая репликация
```bash
python es_replicator.py --config config.yaml
```

### Репликация отсутствующих индексов
```bash
python es_replicator.py --config config.yaml --missing-only
```

### Проверка статуса репликации
```bash
python es_replicator.py --config config.yaml --verify-only
```

### Непрерывная репликация
```bash
python es_replicator.py --config config.yaml --continuous --interval 1800
```

## Параметры командной строки

- `--config`: Путь к конфигурационному файлу (обязательный)
- `--missing-only`: Репликация только отсутствующих индексов
- `--verify-only`: Только проверка статуса репликации
- `--continuous`: Включение непрерывной репликации
- `--interval`: Интервал синхронизации в секундах
- `--timestamp-field`: Пользовательское поле временной метки
- `--exclude-patterns`: Шаблоны индексов для исключения (через запятую)

## Рекомендации по использованию

### Оптимизация производительности
- Настройте `batch_size` в соответствии с размером документов
- Увеличьте `max_workers` при наличии достаточных ресурсов
- Используйте `scroll_time` достаточный для обработки больших индексов
- Отключите `refresh_interval` на целевом индексе во время репликации

### Безопасность
- Используйте HTTPS для подключения к кластерам
- Настройте правильные разрешения для пользователей
- Храните конфигурационный файл в безопасном месте
- Регулярно обновляйте учетные данные

### Мониторинг
- Следите за логами процесса репликации
- Проверяйте статистику обработанных документов
- Настройте оповещения при сбоях репликации
- Регулярно выполняйте проверку целостности данных

## Ограничения
- Максимальный размер batch в Elasticsearch API: 10000 документов
- Требуется достаточно памяти для обработки больших индексов
- Производительность зависит от сетевой связности между кластерами
- Необходимо учитывать версии Elasticsearch на обоих кластерах

## Устранение неполадок

### Частые проблемы
- Таймауты при больших объемах данных
- Ошибки аутентификации
- Проблемы с сетевым подключением
- Несовместимость версий Elasticsearch

### Решения
- Увеличьте значения таймаутов
- Проверьте правильность учетных данных
- Убедитесь в стабильности сетевого соединения
- Проверьте совместимость версий кластеров

## Разработка

### Требования
- Python 3.7+
- elasticsearch-py
- PyYAML
- requests

## Лицензия
GPL v3 License

## Поддержка
При возникновении проблем создавайте issue в репозитории проекта.

## NOTES

### Параллелизм репликации

1. **Параллельные индексы**:
```python
self.max_index_workers = 5  # Количество параллельных индексов
```
Скрипт будет переносить одновременно 5 индексов.

2. **Параллельные потоки для документов**:
```python
self.max_workers = 100    # Увеличиваем количество потоков для документов
```
Для каждого индекса будет использоваться до 100 параллельных потоков для обработки документов.

3. **Размер батча**:
```python
self.batch_size = 10000   # Максимальный размер batch в Elasticsearch
```
Документы обрабатываются пачками по 10,000 штук.

### Расчет времени для 8ТБ данных и 7.5 млрд документов

1. **Ограничения по скорости**:
```python
"indices.recovery.max_bytes_per_sec": "100mb"
```
Максимальная скорость передачи - 100МБ/с на индекс.

2. **Примерные расчеты**:
- 8ТБ = 8192ГБ
- При скорости 100МБ/с на индекс × 5 параллельных индексов = 500МБ/с общая скорость
- Теоретическое минимальное время: 8192ГБ ÷ 0.5ГБ/с ≈ 16384 секунд ≈ 4.5 часа

**НО! Реальное время будет значительно больше** из-за:
1. Накладных расходов на:
   - Создание индексов
   - Маппинги
   - Проверки документов
   - Генерацию хешей
2. Ограничений:
   - Сети
   - Дисковой подсистемы
   - Производительности кластеров

**Реалистичная оценка**:
- Минимум: 12-15 часов
- Максимум: 24-36 часов
- В среднем: около 18-20 часов

**Рекомендации для ускорения**:
1. Увеличить `max_bytes_per_sec` если сеть позволяет
2. Увеличить `max_index_workers` если есть ресурсы
3. Оптимизировать размер батча под ваши документы
4. Проверить настройки refresh_interval
5. Временно уменьшить число реплик в целевом кластере


### На стороне скрипта:

1. **Увеличение max_index_workers**:
```python
self.max_index_workers = 5  # Можно увеличить, например до 10
```
Это параметр скрипта, который контролирует количество параллельно обрабатываемых индексов.

2. **Оптимизация размера батча**:
```python
self.batch_size = 10000   # Больше этого кол-ва эластик не обработает
```
Это тоже параметр скрипта, определяющий сколько документов обрабатывается за раз.

### На стороне Elasticsearch:

1. **Увеличение max_bytes_per_sec**:
```yaml
indices.recovery.max_bytes_per_sec: 100mb  # Можно увеличить до 200mb или выше
```
Это настройка Elasticsearch, которую нужно менять в elasticsearch.yml или через API настроек кластера.

2. **Настройка refresh_interval**:
```yaml
index.refresh_interval: -1  # Во время репликации
```
Это настройка Elasticsearch на уровне индекса. Кстати, скрипт уже автоматически управляет этим параметром:
```python
# В методе replicate_index:
self.target_es.indices.put_settings(
    index=target_index,
    body={"index": {"refresh_interval": "-1"}}
)
```

3. **Уменьшение числа реплик**:
```yaml
index.number_of_replicas: 0
```
Это настройка Elasticsearch, которую нужно применить к целевому кластеру перед началом репликации.

### Рекомендуемый порядок действий:

1. В целевом кластере Elasticsearch:
```bash
# Уменьшаем количество реплик
PUT /_settings
{
  "index": {
    "number_of_replicas": 0
  }
}

# Увеличиваем скорость передачи
PUT /_cluster/settings
{
  "persistent": {
    "indices.recovery.max_bytes_per_sec": "200mb"
  }
}
```

2. В скрипте изменить:
```python
self.max_index_workers = 10  # или больше, зависит от ресурсов
```

После завершения репликации не забудьте вернуть настройки реплик в нормальное состояние в целевом кластере:
```bash
PUT /_settings
{
  "index": {
    "number_of_replicas": 1  # или нужное вам количество
  }
}
```
